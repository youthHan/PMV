<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="Portrait-Mode Video Recognition">
  <meta name="keywords"
    content="Portrait-Mode, Video Recognition, Benchmark, Temporal Distinct, Vertical Videos, Portrait Mode Videos, Action Recognition, Dataset, Portrait-mode Videos, Vertical-orientation, Vertical-orientation Videos">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Video Recognition in Portrait Mode</title>

  <!-- Global site tag (gtag.js) - Google Analytics
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item" href="https://mingfei.info">
          <span class="icon">
            <i class="fas fa-home"></i>
          </span>
        </a>
      </div>
    </div>
  </nav>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Video Recognition in Portrait Mode</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://mingfei.info">Mingfei Han<sup>1,2,3</sup></a>,
              </span>
              <span class="author-block">
                <a href="https://sites.google.com/site/linjieyang89/">Linjie Yang<sup>2</sup></a>,
              </span>
              <span class="author-block">
                <a href="https://airobotai.github.io/jinxiaojie/">Xiaojie Jin<sup>2</sup></a>,
              </span>
              <span class="author-block">
                <a href="https://sites.google.com/site/jshfeng/home">Jiashi Feng<sup>2</sup></a>,
              </span>
              <span class="author-block">
                <a href="https://www.xiaojun.ai/">Xiaojun Chang<sup>1,4</sup></a>,
              </span>
              <span class="author-block">
                <a href="https://hengcv.github.io/">Heng Wang<sup>2</sup></a>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>ReLER, AAII, University of Technology Sydney,</span>
              <span class="author-block"><sup>2</sup>Bytedance Inc.,</span>
              <span class="author-block"><sup>3</sup>Data61, CSIRO,</span>
              <span class="author-block"><sup>4</sup>Department of Computer Vision, MBZUAI</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/pdf/xxx"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span> -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/xxxx"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span> -->
                <!-- Code Link. -->
                <!-- <span class="link-block">
                  <a href="https://github.com/bytedance/Portrait-Mode-Video"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                    </a>
                </span> -->
                <!-- Dataset Link. -->
                <span class="link-block">
                  <a href="https://github.com/bytedance/Portrait-Mode-Video"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Data</span>
                  </a>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <h2 class="subtitle has-text-centered">
          We have developed the first dataset dedicated to portrait mode video recognition, namely PortraitMode-400 and
          focus on the research of this emerging video format.
        </h2>
      </div>
    </div>
  </section>

  <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-huajuan">
            <video poster="" id="huajuan" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/v0d00fg10000cceqgb3c77ub16cnepb0.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-paint2">
            <video poster="" id="paint2" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/v0d00fg10000c4mo34bc77u339ves21g.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-cast-net">
            <video poster="" id="cast-net" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/v0d00fg10000cb5tpjjc77u7h45duqa0.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-firework">
            <video poster="" id="firework" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/v0200fg10000c2hqshct1rmi4vupplog.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-yoga">
            <video poster="" id="yoga" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/v0200fg10000c5r571rc77u4a7dmkc30.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-latte-art">
            <video poster="" id="latte-art" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/v0d00cg10000c3hut6rc77ucgf3rn5tg.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-paint1">
            <video poster="" id="paint1" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/v0200fg10000c9iheb3c77u7bg1k1ok0.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-cross-stitch">
            <video poster="" id="cross-stitch" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/v0200fg10000c98djubc77ufen5979ug.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              The creation of new datasets often presents new challenges for video recognition and can inspire novel
              ideas while addressing these challenges. While existing datasets mainly comprise landscape mode videos,
              our paper seeks to introduce portrait mode videos to the research community and highlight the unique
              challenges associated with this video format. With the growing popularity of smartphones and social
              media applications, recognizing portrait mode videos is becoming increasingly important.
            </p>
            <p>To this end, we have developed the first dataset dedicated to portrait mode video recognition, namely
              PortraitMode-400.
              The taxonomy of PortraitMode-400 was constructed in a data-driven manner, comprising 400 fine-grained
              categories, and rigorous quality assurance was implemented to ensure the accuracy of human annotations.
            </p>
            <p>
              In addition to the new dataset, we conducted a comprehensive analysis of the impact of video format
              (portrait mode versus landscape mode) on recognition accuracy and spatial bias due to the different
              formats.
            </p>
            <p>Furthermore, we designed extensive experiments to explore key aspects of portrait mode video
              recognition, including the choice of data augmentation and evaluation procedure. Building on the
              insights from our experimental results and the introduction of PortraitMode-400, our paper aims to
              inspire further research efforts in this emerging research area.
            </p>
          </div>
        </div>
      </div>
      </br>
      </br>
      <!--/ Abstract. -->

      <!-- Contributions. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">PortraitMode-400</h2>
          <div class="content has-text-justified">
            <p>
              While existing video datasets are mostly built on landscape mode videos, portrait mode videos have become
              increasingly more popular on major social media applications. The shift from landscape mode to portrait
              mode is not just changing the aspect ratios of the videos. It has significant implications for the types
              of content that are created and the spatial bias inherent in the data. 
            </p>
            <p>
              Portrait mode videos bring in distinct challenges for video recognition as well. For example, they tend to focus more on the subject (i.e., typically humans) with much less background context, and include more egocentric content. In addition, they contain a lot of verbal communication that is essential to understand the video content. There is a pressing need for portrait mode video datasets to explore these new research problems.
            </p>
            <p>
              To facilitate the research in portrait mode videos, we introduce the first dataset dedicated to portrait mode video recognition, named PotraitMode-400. Some demo videos are shown above.
            </p>
          </div>
          </br>
          </br>
          <h2 class="title is-3">Portrait Mode vs. Landscape Mode</h2>
          <div class="content has-text-justified">
            <p>
              <strong>Question: </strong>How well does a model trained on landscape mode videos perform on portrait mode
              videos, and vice versa?
            </p>
            <p>
              <strong>Answer: </strong>We investigate this question by constructing a subset from the Kinetics-700
              dataset for a
              rigorous comparison and visualize classification heatmaps to reveal the differences in spatial bias
              resulting from the change in video format.
            </p>
          </div>
          </br>
          </br>
          <h2 class="title is-3">Optimal protocals</h2>
          <div class="content has-text-justified">
            <p>
              <strong>Question: </strong>What are the optimal training and testing protocols for portrait mode video
              recognition?
            </p>
            <p>
              <strong>Answer: </strong>We delve into various components of state-of-the-art deep learning systems, such
              as data augmentation,
              evaluation cropping strategies, etc. Some of our findings contradict the current standard practices
              for landscape mode videos, highlighting the need for further research in the domain of portrait mode
              videos.
            </p>
          </div>
        </div>
      </div>
      <!--/ Contributions. -->


    </div>
  </section>


  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
        @misc{han2023pmv,
          title={Video Recognition in Portrait Mode},
          author={Han, Mingfei and Yang, Linjie and Jin, Xiaojie and Feng, Jiashi and Chang, Xiaojun and Wang, Heng},
          url={"http://mingfei.info/PMV"},
          year={2023},
        }
  </code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              Website design from <a href="https://nerfies.github.io/">Nerfies</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>
